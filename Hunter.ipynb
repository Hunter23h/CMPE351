{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Montreal done\n",
      "New Brunswick done\n",
      "Ottawa done\n",
      "Quebec City done\n",
      "Toronto done\n",
      "Vancouver done\n",
      "Victoria done\n",
      "Winnipeg done\n"
     ]
    }
   ],
   "source": [
    "# Path to the directory containing CSV files\n",
    "folder_path = 'data/'\n",
    "\n",
    "# Initialize an empty dictionary to store dataframes\n",
    "dfs = {}\n",
    "\n",
    "# Loop through files in the directory\n",
    "for file_name in os.listdir(folder_path):\n",
    "    \n",
    "    df = pd.read_csv(folder_path + file_name + '/listings.csv')\n",
    "    print(file_name + ' done')\n",
    "    dfs[file_name] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(df):\n",
    "    # Compute the correlation matrix\n",
    "    correlation_matrix = df.corr()\n",
    "\n",
    "    # Plot the heatmap\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "    plt.title('Correlation Heatmap')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_activity(df):\n",
    "\n",
    "    correlation_matrix = df.corr()\n",
    "\n",
    "    # Check for inverse correlation as well\n",
    "    correlation_with_activity = correlation_matrix['number_of_reviews'].abs().sort_values(ascending=False)\n",
    "    \n",
    "    return correlation_with_activity[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_importance(df):\n",
    "    # Train Random Forest model\n",
    "    X = df.drop(columns=['number_of_reviews'])\n",
    "    y = df['number_of_reviews']\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf.fit(X, y)\n",
    "\n",
    "    # Get feature importances\n",
    "    feature_importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "    sorted_importances = feature_importances.sort_values(ascending=False)\n",
    "\n",
    "    return sorted_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Debug Function\n",
    "def check_null(df):\n",
    "    columns_with_nan = df.columns[df.isna().any()].tolist()\n",
    "    nan_counts = df[columns_with_nan].isna().sum()\n",
    "\n",
    "    for column in columns_with_nan:\n",
    "        print(f\"Column '{column}' has {nan_counts[column]} NaN value(s).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rq1_preprocessing(df):\n",
    "    # Filter columns containing 'host'\n",
    "    host_features = ['host_response_rate', 'host_acceptance_rate',\n",
    "                    'host_listings_count', 'host_total_listings_count', 'host_verifications',\n",
    "                    'host_has_profile_pic', 'host_identity_verified', 'host_is_superhost']\n",
    "\n",
    "    # Select relevant columns from the dataset\n",
    "    df = df[host_features + ['number_of_reviews']]\n",
    "\n",
    "    for col in ['host_response_rate', 'host_acceptance_rate']:\n",
    "        df[col] = df[col].str.rstrip('%').astype(float) / 100.0\n",
    "\n",
    "    df = pd.get_dummies(df, columns=['host_verifications'])\n",
    "\n",
    "    columns_tf = ['host_has_profile_pic', 'host_identity_verified', 'host_is_superhost']\n",
    "    df[columns_tf] = df[columns_tf].replace({'t': 1, 'f': 0, '': 0})\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rq2_preprocessing(df):\n",
    "    # Filter columns containing 'host'\n",
    "    features = ['longitude', 'latitude', 'neighbourhood_cleansed']\n",
    "\n",
    "    # Select relevant columns from the dataset\n",
    "    df = df[features + ['number_of_reviews']]\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    # Fit the LabelEncoder to your data and transform it\n",
    "    df['neighbourhood_cleansed'] = label_encoder.fit_transform(df['neighbourhood_cleansed'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rq3_preprocessing(df):\n",
    "\n",
    "    df['price'] = df['price'].str.replace('$', '').str.replace(',', '').astype(float)\n",
    "    columns_tf = ['host_has_profile_pic', 'host_identity_verified', \"instant_bookable\"]\n",
    "    df[columns_tf] = df[columns_tf].replace({'t': 1, 'f': 0, '': 0})\n",
    "\n",
    "    for col in ['host_response_rate', 'host_acceptance_rate']:\n",
    "        df[col] = df[col].str.rstrip('%').astype(float) / 100.0\n",
    "\n",
    "    df.drop(columns=[\"id\", \"last_scraped\", \"name\", \"host_id\", \"host_name\", \"host_about\", \"host_neighbourhood\", \n",
    "                            \"scrape_id\", \"description\", \"latitude\", \"longitude\", \"has_availability\", \"neighbourhood_group_cleansed\",\n",
    "                            \"bathrooms\", \"bedrooms\", \"calendar_updated\", \"license\"], inplace=True)\n",
    "\n",
    "    df = df.select_dtypes(include='number')\n",
    "\n",
    "    threshold = len(df.columns) / 2\n",
    "\n",
    "    # Filter rows with more than the threshold number of null values\n",
    "    df = df[df.isnull().sum(axis=1) <= threshold]\n",
    "    \n",
    "    df = df.dropna()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_correlation(preprocess_function):\n",
    "\n",
    "    correlations = [] \n",
    "    for city in dfs:\n",
    "        df = preprocess_function(dfs[city].copy())\n",
    "        correlations.append(correlation_activity(df))\n",
    "    average_correlation = pd.concat(correlations).groupby(level=0).mean()\n",
    "    print('Feature Correlation from Correlation Matrix: ')\n",
    "    print(average_correlation.sort_values(ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_importance(preprocess_function):\n",
    "    importances = []  # Initialize a list to store correlation values for each run\n",
    "\n",
    "    for city in dfs:\n",
    "        df = preprocess_function(dfs[city].copy())\n",
    "        if df.empty:\n",
    "            print(f\"Skipping city '{city}' due to empty dataframe.\")\n",
    "            continue\n",
    "        importances.append(model_importance(df))\n",
    "    average_importances = pd.concat(importances).groupby(level=0).mean()\n",
    "\n",
    "    print('\\nFeature Importance from RandomForestRegressor: ')\n",
    "    print(average_importances.sort_values(ascending=False).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Correlation from Correlation Matrix: \n",
      "host_is_superhost            0.249755\n",
      "host_acceptance_rate         0.149762\n",
      "host_listings_count          0.098076\n",
      "host_total_listings_count    0.086380\n",
      "host_response_rate           0.081630\n",
      "Name: number_of_reviews, dtype: float64\n",
      "\n",
      "Feature Importance from RandomForestRegressor: \n",
      "host_acceptance_rate         0.248919\n",
      "host_total_listings_count    0.233011\n",
      "host_listings_count          0.211301\n",
      "host_is_superhost            0.126505\n",
      "host_response_rate           0.070906\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "avg_correlation(rq1_preprocessing)\n",
    "avg_importance(rq1_preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Correlation from Correlation Matrix: \n",
      "latitude                  0.067578\n",
      "neighbourhood_cleansed    0.065007\n",
      "longitude                 0.040826\n",
      "Name: number_of_reviews, dtype: float64\n",
      "\n",
      "Feature Importance from RandomForestRegressor: \n",
      "longitude                 0.488106\n",
      "latitude                  0.478040\n",
      "neighbourhood_cleansed    0.033854\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "avg_correlation(rq2_preprocessing)\n",
    "avg_importance(rq2_preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Correlation from Correlation Matrix: \n",
      "number_of_reviews_ltm     0.637376\n",
      "reviews_per_month         0.517382\n",
      "number_of_reviews_l30d    0.327071\n",
      "host_acceptance_rate      0.135894\n",
      "availability_365          0.133873\n",
      "Name: number_of_reviews, dtype: float64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importance from RandomForestRegressor: \n",
      "number_of_reviews_ltm          0.442519\n",
      "reviews_per_month              0.122443\n",
      "maximum_nights                 0.046030\n",
      "review_scores_communication    0.041919\n",
      "review_scores_checkin          0.032210\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "avg_correlation(rq3_preprocessing)\n",
    "avg_importance(rq3_preprocessing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
